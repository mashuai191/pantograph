{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pantograph Demo - segmentation+localization",
      "provenance": [],
      "authorship_tag": "ABX9TyN8G/kbbgcoeyoVzKHZ5rbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mashuai191/pantograph/blob/master/Pantograph_Demo_segmentation%2Blocalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClKFptM_trgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how to run web app in google colab\n",
        "    #refer to : https://medium.com/@kshitijvijay271199/flask-on-google-colab-f6525986797b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbZ2f04LErRS",
        "colab_type": "code",
        "outputId": "e76037e7-ef69-4599-d38b-c8db94364a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "#!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "#!pip install torch torchvision\n",
        "!pip install numpy\n",
        "!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.16)\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-gy47gwe4\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-gy47gwe4\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.16)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275297 sha256=832f2aff2423c9645cad9457eb336507a4400792d0f0099a9389e8dbd7ed8e30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lij94tbf/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pycocotools"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUQWr6-GRQJ",
        "colab_type": "text"
      },
      "source": [
        "## install Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISXWbjmsEt9G",
        "colab_type": "code",
        "outputId": "addaa02e-5a69-4033-feb5-ae16933364f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "\n",
        "!rm -rf detectron2_repo\n",
        "!git clone https://github.com/mashuai191/detectron2 detectron2_repo\n",
        "\n",
        "!pip install -e detectron2_repo\n",
        "\n",
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detectron2_repo'...\n",
            "remote: Enumerating objects: 3563, done.\u001b[K\n",
            "remote: Total 3563 (delta 0), reused 0 (delta 0), pack-reused 3563\u001b[K\n",
            "Receiving objects: 100% (3563/3563), 2.14 MiB | 1.91 MiB/s, done.\n",
            "Resolving deltas: 100% (2458/2458), done.\n",
            "Obtaining file:///content/detectron2_repo\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (7.0.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (0.1.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (0.8.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (3.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (4.38.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (2.2.0)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (0.1.dev200325)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1.1) (5.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.1) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.1) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.1) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1.1) (2.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (1.27.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (1.6.0.post2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (1.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (1.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (0.34.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1.1) (46.0.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore->detectron2==0.1.1) (1.6.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (3.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1) (3.1.0)\n",
            "Installing collected packages: detectron2\n",
            "  Found existing installation: detectron2 0.1.1\n",
            "    Can't uninstall 'detectron2'. No files were found to uninstall.\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed detectron2\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eEpVHfVFMAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pitw31mjHZhN",
        "colab_type": "text"
      },
      "source": [
        "## mount gdrive for dataset and weight file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbQ-EXzY8EPB",
        "colab_type": "code",
        "outputId": "beaa4389-929b-4339-b6ba-3d032d099af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nr5Y8OyGgWU",
        "colab_type": "text"
      },
      "source": [
        "## install yolo v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoGZpxcmGkjP",
        "colab_type": "code",
        "outputId": "8a182339-43bf-4dad-9c5e-636058ac75f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!rm pantograph -rf\n",
        "!git clone 'https://github.com/mashuai191/pantograph.git'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pantograph'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 92 (delta 29), reused 62 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgrPJ3lxG0kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/App/machine_learning/cv/shanghaidianqi_line5/yolo3/qingsong/yolo.h5' /content/pantograph/localization_yolo3/model_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPl6OQomG5Do",
        "colab_type": "code",
        "outputId": "abfd4ec6-bb19-414e-fbaf-eb818eb3c4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/pantograph/localization_yolo3')\n",
        "\n",
        "from yolo import YOLO\n",
        "\n",
        "yolo = YOLO()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "/content/pantograph/localization_yolo3/model_data/yolo.h5 model, anchors, and classes loaded.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qu_zXgSD90r",
        "colab_type": "code",
        "outputId": "39c8b722-46c7-4ffa-be7d-0f7f0e911c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip list | grep tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow          0.1.12          \n",
            "tensorflow               1.15.2          \n",
            "tensorflow-addons        0.8.3           \n",
            "tensorflow-datasets      2.1.0           \n",
            "tensorflow-estimator     1.15.1          \n",
            "tensorflow-gan           2.0.0           \n",
            "tensorflow-gcs-config    2.1.8           \n",
            "tensorflow-hub           0.7.0           \n",
            "tensorflow-metadata      0.21.1          \n",
            "tensorflow-privacy       0.2.2           \n",
            "tensorflow-probability   0.7.0           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh3tIsZxt3iH",
        "colab_type": "code",
        "outputId": "c0fe2ee9-d168-4d2c-c767-a688b5b81068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install flask-ngrok\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcoSmbKoUt4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import atexit\n",
        "import json\n",
        "import os\n",
        "import platform\n",
        "import shutil\n",
        "import subprocess\n",
        "import tempfile\n",
        "import time\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from threading import Timer\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "def _get_command():\n",
        "    system = platform.system()\n",
        "    if system == \"Darwin\":\n",
        "        command = \"ngrok\"\n",
        "    elif system == \"Windows\":\n",
        "        command = \"ngrok.exe\"\n",
        "    elif system == \"Linux\":\n",
        "        command = \"ngrok\"\n",
        "    else:\n",
        "        raise Exception(\"{system} is not supported\".format(system=system))\n",
        "    return command\n",
        "\n",
        "\n",
        "def _run_ngrok(port):\n",
        "    command = _get_command()\n",
        "    ngrok_path = str(Path(tempfile.gettempdir(), \"ngrok\"))\n",
        "    _download_ngrok(ngrok_path)\n",
        "    executable = str(Path(ngrok_path, command))\n",
        "    os.chmod(executable, 0o777)\n",
        "    ngrok = subprocess.Popen([executable, 'http', str(port)])\n",
        "    atexit.register(ngrok.terminate)\n",
        "    localhost_url = \"http://localhost:4040/api/tunnels\"  # Url with tunnel details\n",
        "    time.sleep(1)\n",
        "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
        "    j = json.loads(tunnel_url)\n",
        "\n",
        "    tunnel_url = j['tunnels'][0]['public_url']  # Do the parsing of the get\n",
        "    tunnel_url = tunnel_url.replace(\"https\", \"http\")\n",
        "    return tunnel_url\n",
        "\n",
        "\n",
        "def _download_ngrok(ngrok_path):\n",
        "    if Path(ngrok_path).exists():\n",
        "        return\n",
        "    system = platform.system()\n",
        "    if system == \"Darwin\":\n",
        "        url = \"https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-darwin-amd64.zip\"\n",
        "    elif system == \"Windows\":\n",
        "        url = \"https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-amd64.zip\"\n",
        "    elif system == \"Linux\":\n",
        "        url = \"https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\"\n",
        "    else:\n",
        "        raise Exception(f\"{system} is not supported\")\n",
        "    download_path = _download_file(url)\n",
        "    with zipfile.ZipFile(download_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(ngrok_path)\n",
        "\n",
        "\n",
        "def _download_file(url):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    r = requests.get(url, stream=True)\n",
        "    download_path = str(Path(tempfile.gettempdir(), local_filename))\n",
        "    with open(download_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    return download_path\n",
        "\n",
        "\n",
        "def start_ngrok(port):\n",
        "    ngrok_address = _run_ngrok(port)\n",
        "    print(f\" * Running on {ngrok_address}\")\n",
        "    print(f\" * Traffic stats available on http://127.0.0.1:4040\")\n",
        "\n",
        "\n",
        "def run_with_ngrok(app):\n",
        "    \"\"\"\n",
        "    The provided Flask app will be securely exposed to the public internet via ngrok when run,\n",
        "    and the its ngrok address will be printed to stdout\n",
        "    :param app: a Flask application object\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    old_run = app.run\n",
        "\n",
        "    def new_run(*args, **kwargs):\n",
        "        port = kwargs.get('port', 5000)\n",
        "        thread = Timer(1, start_ngrok, args=(port,))\n",
        "        thread.setDaemon(True)\n",
        "        thread.start()\n",
        "        old_run(*args, **kwargs)\n",
        "    app.run = new_run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2DkdWFqt4JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h1>Running Flask on Google Colab!</h1>\"\n",
        "  \n",
        "#app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItGuf2HG14A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pysb181s85Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "DIR_BASE = '/content/gdrive/My Drive/App/machine_learning/cv/shanghaidianqi_line5'\n",
        "DIR_DATASET = '20181117_03_08_1750_G1380.MP4'\n",
        "DIR_DATASET2 = 'night.mp4'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XgqHPs1RouM",
        "colab_type": "code",
        "outputId": "d39b2d3e-b03f-481a-a4aa-230a52146c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-rm_qvwcbG2",
        "colab_type": "code",
        "outputId": "cf4cd369-0d7a-497e-c6ad-381e82762277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!rm -rf flask-video-streaming\n",
        "!git clone https://github.com/mashuai191/flask-video-streaming.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flask-video-streaming'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 99 (delta 6), reused 4 (delta 1), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (99/99), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hItciab0QiNV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W4hnUy6cf42",
        "colab_type": "code",
        "outputId": "b82d13a4-6ca9-4031-c453-422a2b09b82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd flask-video-streaming"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/flask-video-streaming\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDksgiBmUamf",
        "colab_type": "code",
        "outputId": "de100858-1130-4e06-9e2e-f9c4b245d834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.jpg\tbase_camera.py\t  LICENSE\t\t   requirements.txt\n",
            "2.jpg\tcamera_opencv.py  README.md\t\t   templates\n",
            "3.jpg\tcamera_pi.py\t  requirements-opencv.txt\n",
            "app.py\tcamera.py\t  requirements-pi.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zAT1Z6Kc4aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from base_camera import BaseCamera\n",
        "\n",
        "class segCamera(BaseCamera):\n",
        "    video_source = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        if os.environ.get('OPENCV_CAMERA_SOURCE'):\n",
        "            segCamera.set_video_source(int(os.environ['OPENCV_CAMERA_SOURCE']))\n",
        "        super(segCamera, self).__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def set_video_source(source):\n",
        "        segCamera.video_source = source\n",
        "\n",
        "    @staticmethod\n",
        "    def frames():\n",
        "        #camera = cv2.VideoCapture(Camera.video_source)\n",
        "        camera = cv2.VideoCapture(os.path.join(DIR_BASE, DIR_DATASET))\n",
        "        if not camera.isOpened():\n",
        "            raise RuntimeError('Could not start camera.')\n",
        "\n",
        "        #import torch\n",
        "        import multiprocessing\n",
        "        print(\"11111\", multiprocessing.get_start_method())\n",
        "        #torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "        \n",
        "        MetadataCatalog.get(\"balloon_\" + 'test').set(thing_classes=[\"balloon\"])\n",
        "        cfg = get_cfg()\n",
        "        # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "        # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "        #cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "        #cfg.OUTPUT_DIR = \"pre-trained models/model_final_R50_x3_ratio012.pth\"\n",
        "        cfg.MODEL.WEIGHTS = os.path.join(DIR_BASE, \"trained_models/model_final_R50_x3_ratio012.pth\")\n",
        "        cfg.DATASETS.TEST = (\"balloon_test\", )\n",
        "        cfg.DATASETS.TRAIN = (\"balloon_test\", )\n",
        "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n",
        "\n",
        "        predictor = DefaultPredictor(cfg)\n",
        "\n",
        "        print(\"22222\", torch.multiprocessing.get_start_method())\n",
        "\n",
        "\n",
        "        while True:\n",
        "            # read current frame\n",
        "            _, img = camera.read()\n",
        "            cropped_image = img[200:625, 200:1150]\n",
        "            print (\"seg:\", img.shape, cropped_image.shape)\n",
        "            \n",
        "\n",
        "            # let's predict\n",
        "\n",
        "            #outputs = predictor(cropped_image)\n",
        "\n",
        "            #v = Visualizer(cropped_image[:, :, ::-1], metadata=MetadataCatalog.get(\"balloon_\" + 'test'), scale=1.2)\n",
        "            #v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "            #img_tmp = v.get_image()[:, :, ::-1]\n",
        "            #cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "            #imS = cv2.resize(img_tmp, (350, 250))\n",
        "            imS = cv2.resize(img, (100, 50))\n",
        "            #print (imS.shape)\n",
        "\n",
        "            # encode as a jpeg image and return it\n",
        "            yield cv2.imencode('.jpg', imS)[1].tobytes()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2K21vlmQvYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "\n",
        "from base_camera import BaseCamera\n",
        "\n",
        "\n",
        "class locCamera(BaseCamera):\n",
        "    video_source = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        if os.environ.get('OPENCV_CAMERA_SOURCE'):\n",
        "            locCamera.set_video_source(int(os.environ['OPENCV_CAMERA_SOURCE']))\n",
        "        super(locCamera, self).__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def set_video_source(source):\n",
        "        locCamera.video_source = source\n",
        "\n",
        "    @staticmethod\n",
        "    def frames():\n",
        "        #camera = cv2.VideoCapture(Camera.video_source)\n",
        "        camera = cv2.VideoCapture(os.path.join(DIR_BASE, DIR_DATASET2))\n",
        "        if not camera.isOpened():\n",
        "            raise RuntimeError('Could not start camera.')\n",
        "\n",
        "        while True:\n",
        "            # read current frame\n",
        "            _, img = camera.read()\n",
        "\n",
        "            # = img[200:625, 200:1150]\n",
        "            \n",
        "            # let's predict\n",
        "            image = Image.fromarray(img)\n",
        "            image = yolo.detect_image(image)\n",
        "            result = np.asarray(image)\n",
        "\n",
        "            #v = Visualizer(cropped_image[:, :, ::-1], metadata=MetadataCatalog.get(\"balloon_\" + 'test'), scale=1.2)\n",
        "            #v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "            #img_tmp = v.get_image()[:, :, ::-1]\n",
        "            #cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "            imS = cv2.resize(result, (350, 250))\n",
        "            #imS = cv2.resize(img, (200, 100))\n",
        "            print (\"loc:\", img.shape, imS.shape)\n",
        "\n",
        "            # encode as a jpeg image and return it\n",
        "            yield cv2.imencode('.jpg', imS)[1].tobytes()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vugGtrmt_8Z",
        "colab_type": "code",
        "outputId": "8d2c3b5c-b24d-45e2-d79c-20195af73330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!/usr/bin/env python\n",
        "from importlib import import_module\n",
        "import os\n",
        "from flask import Flask, render_template, Response\n",
        "import multiprocessing as mp\n",
        "mp.set_start_method('spawn',force=True)\n",
        "    \n",
        "\n",
        "\n",
        "# import camera driver\n",
        "if os.environ.get('CAMERA'):\n",
        "    Camera = import_module('camera_' + os.environ['CAMERA']).Camera\n",
        "else:\n",
        "    from camera import Camera\n",
        "\n",
        "# Raspberry Pi camera module (requires picamera package)\n",
        "# from camera_pi import Camera\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Video streaming home page.\"\"\"\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "def gen(camera):\n",
        "    \"\"\"Video streaming generator function.\"\"\"\n",
        "    while True:\n",
        "        frame = camera.get_frame()\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
        "\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
        "    print ('video_feed, pid {}'.format(os.getpid()))\n",
        "    import torch\n",
        "    print(\"reg process\", torch.multiprocessing.get_start_method())\n",
        "    #torch.multiprocessing.set_start_method('forkserver', force=True)\n",
        "\n",
        "    return Response(gen(segCamera()),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "@app.route('/video_feed1')\n",
        "def video_feed1():\n",
        "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
        "    print ('video_feed1, pid {}'.format(os.getpid()))\n",
        "    \n",
        "    #torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "    return Response(gen(Camera()),\n",
        "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    app.run(host='0.0.0.0', threaded=True)\n",
        "#from flask.flask_script import Manager\n",
        "\n",
        "#manager = Manager(app)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#    manager.run(host='0.0.0.0', threaded=True)\n",
        "    print ('main, pid {}'.format(os.getpid()))\n",
        "\n",
        "    #import torch\n",
        "    #torch.multiprocessing.set_start_method('forkserver', force=True)\n",
        "    #mp.set_start_method('spawn',force=True)\n",
        "    print (mp.get_start_method())\n",
        "    #mp.set_start_method('spawn')\n",
        "    #mp = torch.multiprocessing.get_context('spawn')\n",
        "    #torch.multiprocessing.set_start_method('spawn')\n",
        "    #torch.multiprocessing.set_start_method('forkserver', force=True)\n",
        "    app.run(host='0.0.0.0', threaded=False, processes=2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main, pid 1382\n",
            "spawn\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://37115fa7.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [06/Apr/2020 14:40:50] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "video_feed, pid 1741\n",
            "reg process spawn\n",
            "Camera init.\n",
            "pid  1741 tid  140156196087680\n",
            "Starting camera thread.\n",
            "video_feed1, pid 1744\n",
            "Camera init.\n",
            "pid  1744 tid  140156196087680\n",
            "Starting camera thread.\n",
            "11111 spawn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-7:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/flask-video-streaming/base_camera.py\", line 97, in _thread\n",
            "    for frame in frames_iterator:\n",
            "  File \"<ipython-input-16-95b269c1163b>\", line 42, in frames\n",
            "    predictor = DefaultPredictor(cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/engine/defaults.py\", line 163, in __init__\n",
            "    self.model = build_model(self.cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/build.py\", line 19, in build_model\n",
            "    return META_ARCH_REGISTRY.get(meta_arch)(cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/rcnn.py\", line 41, in __init__\n",
            "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(num_channels, 1, 1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\", line 197, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: cuda runtime error (3) : initialization error at /pytorch/aten/src/THC/THCGeneral.cpp:54\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "video_feed, pid 1771\n",
            "reg process spawn\n",
            "Camera init.\n",
            "pid  1771 tid  140156196087680\n",
            "Starting camera thread.\n",
            "11111 spawn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [06/Apr/2020 14:40:54] \"\u001b[37mGET /video_feed1 HTTP/1.1\u001b[0m\" 200 -\n",
            "Exception in thread Thread-7:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/flask-video-streaming/base_camera.py\", line 97, in _thread\n",
            "    for frame in frames_iterator:\n",
            "  File \"<ipython-input-16-95b269c1163b>\", line 42, in frames\n",
            "    predictor = DefaultPredictor(cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/engine/defaults.py\", line 163, in __init__\n",
            "    self.model = build_model(self.cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/build.py\", line 19, in build_model\n",
            "    return META_ARCH_REGISTRY.get(meta_arch)(cfg)\n",
            "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/rcnn.py\", line 41, in __init__\n",
            "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(num_channels, 1, 1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\", line 197, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: cuda runtime error (3) : initialization error at /pytorch/aten/src/THC/THCGeneral.cpp:54\n",
            "\n",
            "127.0.0.1 - - [06/Apr/2020 14:41:03] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ySK_GleEnlf",
        "colab_type": "code",
        "outputId": "fad6178a-bdc3-4a12-f480-33a8cfe20783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr  6 14:40:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    31W / 250W |   1323MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFnwON9RpllL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtPCFBYU0QuX",
        "colab_type": "text"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9h3kjQMRYuP",
        "colab_type": "text"
      },
      "source": [
        "1. if in main: set_start_method('spawn', force=True), main forkspawn\n",
        "\n",
        "```\n",
        "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/rcnn.py\", line 41, in __init__\n",
        "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(num_channels, 1, 1)\n",
        "  File \"/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\", line 195, in _lazy_init\n",
        "    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n",
        "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "2. if in sub-process: torch.multiprocessing.set_start_method, \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
        "\n",
        "```\n",
        "\n",
        "3. main python  multiprocessing.set_start_method, 2 \n",
        "\n",
        "4. main global \n",
        "\n",
        "```\n",
        "import multiprocessing as mp\n",
        "mp.set_start_method('spawn',force=True)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  File \"<ipython-input-22-95b269c1163b>\", line 42, in frames\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "  File \"/content/detectron2_repo/detectron2/engine/defaults.py\", line 163, in __init__\n",
        "    self.model = build_model(self.cfg)\n",
        "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/build.py\", line 19, in build_model\n",
        "    return META_ARCH_REGISTRY.get(meta_arch)(cfg)\n",
        "  File \"/content/detectron2_repo/detectron2/modeling/meta_arch/rcnn.py\", line 41, in __init__\n",
        "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).to(self.device).view(num_channels, 1, 1)\n",
        "  File \"/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\", line 197, in _lazy_init\n",
        "    torch._C._cuda_init()\n",
        "RuntimeError: cuda runtime error (3) : initialization error at /pytorch/aten/src/THC/THCGeneral.cpp:54\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfH8KJFtB_ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}